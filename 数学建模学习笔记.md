# 数学建模

思路：

- 找有无相似问题（可借鉴）
- 问题分解，逐个攻破
- 考虑极限情况（理想状态）
- 综合问题给的条件
- 先简后繁

流程：

1. 问题分析：了解背景，明确建模目的，搜索相关信息
2. 模型假设：假设模型的异常/不可测量的情况
3. 建立模型：用数学符号来表达，公式
4. 模型求解：借助其他软件平台求解公式、参数
5. 模型分析：分析求解结果
6. 模型验证：验证模型（$R^2$ 残差等）
7. 模型应用：用在哪，怎么用
8. 模型评价：模型的好与坏

# 1. 层次分析法

主要用于解决**评价类**问题（例如：选择哪种方案最好，哪个员工表现最佳）

解决评价类问题，首先要想到以下三个问题：

1. 我们评价的目标是什么？
2. 我们为了达到这个目标有哪几种可选的方案？
3. 评价的准则或指标是什么？（我们根据什么东西来评价好坏）
   - 如果题目没给则需要自己确定。

**首先**，我们可以百度或者在背景材料中提取准则或指标。推荐去 知网、万方、百度学术 搜索相关论文。

**其次**，对这些指标跟可选方案进行建表：

|     | 指标权值    | 可选方案1 | 可选方案2 | 可选方案3…    |
| --- | ------- | ----- | ----- | --------- |
| 指标1 |         |       |       | 指标1的总和要为1 |
| 指标2 |         |       |       | 指标2的总和要为1 |
| 指标3 |         |       |       | 指标3的总和要为1 |
| ….. | 权重总和要为1 |       |       |           |

***

**第三步**，计算权重。

如果直接对很多个指标的权重进行计算，那么可能会出现考虑不周的情况。由此我们可以对指标两两进行比较，然后在整合成一张大表。这也是层次分析法的思想。

通常我们会对每个指标进行打分的方式来进行计算权重。

| 标度      | 含义                       |
|:-------:|:------------------------:|
| 1       | 表示两个因素相比，同样重要            |
| 3       | 一个因素比另一个因素稍微重要           |
| 5       | 一个因素比另一个因素明显重要           |
| 7       | 一个因素比另一个因素强烈重要           |
| 9       | 一个因素比另一个因素极端重要           |
| 2,4,6,8 | 上述两相邻判断的中值               |
| 倒数      | A和B相比如果标度为3，那么B和A相比就是1/3 |

比如现在对下列指标进行打分。

|     | 景色  | 花费  | 居住  |
|:---:|:---:|:---:|:---:|
| 景色  | 1   | 1/2 | 4   |
| 花费  | 2   | 1   | 7   |
| 居住  | 1/4 | 1/7 | 1   |

若把表格记为A，对应元素为`aij`，那么`aij` 表示的意思是，与指标`j` 相比，`i` 的重要程度

很明显，对角线肯定是1，因为自己对自己来说肯定是同样重要的。

`a21` 则表示花费对景色来说略微重要，相反，在`a12` 的位置就是它的倒数即1/2。

观察上面的方阵，有如下特点：

1. `aij` 表示的意思是，与指标`j` 相比，`i` 的重要程度
2. 当`i=j`时，两个指标相同，记为1。
3. `aij` > 0且满足 `aij × aji = 1` （我们称满足这一条件的矩阵为**正互反矩阵**）

实际上，此矩阵就是层级分析法中的**判断矩阵**。

上面只是完成了判断矩阵，如何进行计算权重，后面再讲。

现在先来做 可选方案在每个指标所占的分数。

| 景色  | 西河  | 东湖  | 桂林  |
|:---:|:---:|:---:|:---:|
| 西河  | 1   | 2   | 5   |
| 东湖  | 1/2 | 1   | 2   |
| 桂林  | 1/5 | 1/2 | 1   |

其他指标以此类推。

接下来讨论一下可能出问题的地方。

比如把上表改成这样：

| 景色  | 西河  | 东湖  | 桂林  |
|:---:|:---:|:---:|:---:|
| 西河  | 1   | 2   | 1   |
| 东湖  | 1/2 | 1   | 2   |
| 桂林  | 1   | 1/2 | 1   |

此表说明，西河>东湖，西河=桂林 而 东湖>桂林，出现了矛盾之处。

此矩阵就是不一致矩阵。相反，我们往往需要的是 **一致矩阵** 或者尽量接近一致矩阵。

**一致矩阵的特点：在各行（各列）之间成倍数关系。** 

所以，在使用判断矩阵计算权重之前，必须对其进行`一致性检验`。

一致性检验的步骤：

1. 计算**`一致性指标CI`**：`CI = (λmax-n)/(n-1)` λmax为最大特征值

2. 查找对应**`平均随机一致性指标RI`** 
   
   ![image-20200811220803440](数学建模学习笔记.assets/image-20200811220803440.png)

3. 计算**`一致性比例CR`** ：`CR=CI/RI`

如果**`CR<0.1`**,则认为判断矩阵的一致性可以接受；否则需要对其进行修正。如何修正呢，尽量往倍数关系那靠。

那判断矩阵如何计算权重呢？有三种方法：算术平均法、几何平均法、特征值法。

以下表为例：

| 景色  | 西河  | 东湖  | 桂林  |
|:---:|:---:|:---:|:---:|
| 西河  | 1   | 2   | 5   |
| 东湖  | 1/2 | 1   | 2   |
| 桂林  | 1/5 | 1/2 | 1   |

**算术平均法**：

第一步：对每一列进行归一化处理

```
第一列：
西河 = 1/(1+0.5+0.2) = 0.5882
东湖 = 0.5/(1+0.5+0.2) = 0.2941
桂林 = 0.2/(1+0.5+0.2) = 0.1177
第二列：
西河 = 2/（2+1+0.5）= 0.5714
东湖 = 1/（2+1+0.5）= 0.2857
桂林 = 0.5/（2+1+0.5）= 0.1429
第三列：
西河 = 5/（5+2+1）= 0.625
东湖 = 2/（5+2+1）= 0.25
桂林 = 1/（5+2+1）= 0.125
```

第二步：求平均权重

```
综合上述三列，我们求平均权重
西河 =（0.5882+0.5714+0625）/3 =05949
东湖 =（0.2941+0.2857+025）/3 =02766
桂林 =（0.1177+01429+0125）/3 =01285
```

**特征值法**：

第一步：求出矩阵A的最大特征值以及其对应的特征向量

第二步：对求出的特征向量进行归一化即可得到我们的权重

最后，到这一步就可以填完一开始的表格了，然后计算出每个可选方案的得分。

***

**总结**：

第一步：分析系统中各因素之间的关系，建立系统的递阶**层次结构**。要画图

第二步：对于同一层次的各元素关于上一层次中某一准则的重要性进行两两比较，构造出判断矩阵.

第三步：进行一致性检验然后计算出相对权重。

​                三种方法计算权重：（1）算术平均法（2）几何平均法（3）特征值法

```
为了保证结果的稳健性，本文采用了三种方法分别求出了权重，再根据得到的权重矩阵计算各方案的得分，并进行排序和综合分析，这样避免了采用单一方法所产生的偏差，得出的结论将更全面、更有效。
```

第四步：计算各层元素对系统目标的合成权重，并进行排序。（最好再画条形图）

**局限性**：评价的决策层不能太多，太多的话n会很大，判断矩阵和一致矩阵差异可能会很大。

而有些时候，并不是每个指标都对着每个可选方案。而是可能一对一或者多对一等情况。

![image-20200721085726229](数学建模学习笔记.assets/image-20200721085726229.png)

# 2. 优劣解距离法

作用：评价方案的优劣、评价每个样本的好坏。

也叫`TOPSIS` 方法。该方法对数据分布及样本含量没有严格限制，数据计算简单易行。

先解释一些专业名词：

| 指标名称     | 指标特点          | 例子            |
| -------- | ------------- | ------------- |
| 极大型（效益型） | 指标越大（多）越好     | 成绩、GDP增速、企业利润 |
| 极小型（成本型） | 指标越小（少）越好     | 费用、坏品率、污染程度   |
| 中间型指标    | 越接近某个值(最佳值)越好 | 水质量评估时的PH值    |
| 区间型指标    | 落在某个区间最好      | 体温、水中植物性营养物量  |

`正向化`：将所有的指标转化为**极大型**称为指标正向化（最常用）

**级小型 → 极大型** 公式：**`max - x`**

**中间型指 → 极大型指标** 公式：

![image-20200615232843158](数学建模.assets/image-20200615232843158.png)

**区间型指标 → 标极大型指标** 公式：

![image-20200615233235769](数学建模.assets/image-20200615233235769.png)

`标准化处理`：对**已经正向化**的矩阵消去不同指标量纲(单位)的影响。标准化的目的是**消除不同指标量纲的影响**。

![image-20200615230653495](数学建模.assets/image-20200615230653495.png)

<u>注意：以上的公式都不是唯一的。</u>

（可以用`Z-标准化`，即每个元素减去均值除以方差，matlab中有`zscore(x)` 可以求出x矩阵的标准化）

`TOPSIS` 的基本过程为：

1. 为先将原始数据矩阵统一指标类型（一般正向化处理得到**正向化**的矩阵）
2. 再对正向化的矩阵进行**标准化**处理以消除各指标量纲的影响，并找到有限方案中的最优方案和最劣方案
3. 分别计算各评价对象与最优方案和最劣方案间的距离
   - ![image-20200616105512935](数学建模.assets/image-20200616105512935.png)
4. 获得各评价对象与最优方案的相对接近程度（即给每个对象打分），以此作为评价优劣的依据
   - ![image-20200616105548640](数学建模.assets/image-20200616105548640.png)

`Zj+`为每个指标的最大值，`Zj-`为每个指标的最小值，`zij`为第`j` 指标的第`i` 对象的值。`wj` 为 每个指标的权重。

**最后可以将S进行归一化**。

## 2.1 熵权法确定权重

> 确定权重可以使用层次分析法或者熵权法

熵权法是一种客观赋权方法。

依据的**原理**：指标的变异程度越小，所反映的信息量也越少，其对应的权值也应该越低。

**缺点**：如果对于所有的样本而言，这个指标都是相同的数值，则熵权法会指定该指标的权重为0，而该指标在现实常识中的权重却很高，这时就会出现计算错误的情况。

如何度量**信息量**的大小？越有可能发生的事情，信息量越少，越不可能发生的事情，信息量就越多

如果把**信息量**用字母`I`表示，**概率**用`p`表示，那么我们可以将它们建立一个函数关系

![image-20200719124030285](数学建模学习笔记.assets/image-20200719124030285.png)

![image-20200719124044091](数学建模学习笔记.assets/image-20200719124044091.png)

![image-20200719124133521](数学建模学习笔记.assets/image-20200719124133521.png)

**【注意】信息熵越大则已知的信息量越小。** 

熵权法计算步骤：

1. 判断输入的矩阵中是否存在负数，如果有则要重新标准化到非负区间。
   
   ![image-20200719124733917](数学建模学习笔记.assets/image-20200719124733917.png)

2. 计算第`j`项指标下第`i`个样本所占的比重，并将其看作相对熵计算中用到的概率
   
   ![image-20200720090336990](数学建模学习笔记.assets/image-20200720090336990.png)

3. 计算每个指标的信息熵，并计算信息效用值，并归一化得到每个指标的熵权
   
   ![image-20200719125100399](数学建模学习笔记.assets/image-20200719125100399.png)

# 3. 插值算法

> 在数学建模中，插值算法一般用来补全数据。

所谓插值，就是根据已知的点（称为**插值节点**），求出一个经过这些点的函数（称为**插值函数**）后，再对给定条件的x根据函数求其对应y值。比如，给出过去十年的人口数量，求未来几年的人口数量。过去十年跟过去十年的人口数量就是已知点，未来几年就是给定条件的x，未来几年人口的数量就是其对应的y值。

求插值函数的方法有很多，主要有：

- 分段插值：将点进行分组，每组分别用不同的多项式。分段n次插值就表示每组的点之间使用n次多项式来对x求y值。例如分段二次插值，则每组的点的插值函数为`a0+a1*x1+a2*x2^2` 
- 插值多项式：`P(x)=a0+a1*x+…+an*x^n` 的形式

拉格朗日插值法跟牛顿插值法在高次插值(即很多已知点)时都会产生**龙格现象**，并且都不能全面反映被插值函数的性态。龙格现象就是求出来的插值函数两端处波动极大，产生明显的震荡。

![image-20200624231931567](数学建模.assets/image-20200624231931567.png)

因此，在建模中一般都采用**分段三次埃尔米特插值法**跟**三次样条插值法**。

## 3.1 分段三次埃尔米特

埃尔米特插值多项式：不但要求在节点上的函数值相等，而且还要求对应的导数值也相等甚至要求高阶导数也相等。保持插值曲线在节点处有更光滑，使插值函数和被插函数的密和程度更好。

但是，直接使用 Hermite插值得到的多项式次数较高，也存在着龙格现象，因此在实际应用中，往往使用分段三次 Hermite插值多项式（PCHIP）。

在Matlab中有PCHIP的内置函数：

**pchip(x,y,target_x)** xy为已知点，target_x为要计算的x值

```matlab
% 分段三次埃尔米特插值
x = -pi:pi; y = sin(x); 
target_x = -pi:0.1:pi;
p = pchip(x,y,target_x);
figure(1); % 在同一个脚本文件里面，要想画多个图，需要给每个图编号，否则只会显示最后一个图
plot(x, y, 'o', target_x, p, 'r-')
```

## 3.2 三次样条插值

**spline(x, y, target_x)** xy为已知点，target_x为要计算的x值

**interpn (x, y, target_x, 'spline')** 与上者等价

# 4. 拟合算法

> 在数学建模中，拟合算法可以用来查看趋势、求解函数的未知参数等

拟合跟插值类似，只不过拟合求得的函数不需要经过已知点（样本点），接近就行。

拟合中一般函数的大致形式是我们自己给定的，比如我们根据已知点给出假定说：此函数（拟合曲线）为`y=kx+b`，此时我们就可以利用拟合算法来求出参数k和b。

**最小二乘法**的思想：当所有样本点与拟合曲线距离之和最短时求得拟合曲线的参数。

如何求每个样本点与拟合曲线的距离？很简单，直接 **($y_i$- $\hat y$) $^2$** 。

那如何求所有样本点与拟合曲线的距离之和呢？很简单，直接将上面公式求和 **$\sum_{i=1}^n$ ($y_i$- $\hat y$) $^2$** 

那专业术语是如何表达距离之和最小时求得的参数值呢？**$\hat k$,$\hat b$ = $arg\,\min_{\hat k \hat b}$ ($\sum_{i=1}^n$ (**$y_i$- $\hat y$**) $^2$ )** 

![image-20200716111739028](数学建模学习笔记.assets/image-20200716111739028.png)

思考：为什么求样本点与拟合曲线的距离时不使用绝对值、三次方或四次方，一定要二次方呢？

1. 使用绝对值时有一点处是不可导的。
2. 使用三次方时，误差会正负相抵。
3. 使用四次方时，容易造成极端数据对拟合曲线的影响。

由于拟合曲线的大致形式是我们自己猜测的，所有有时候与样本点相差甚远，那我们该如何评价拟合的好坏呢？（即判断我们猜测的函数是否合理）

首先来看一下一些专业名词的定义：

- 总体平方和`SST`：**SST = $\sum_{i=1}^n$ ($y_i$- $\overline y$) $^2$** 
- 误差平方和`SSE`：**SSE = $\sum_{i=1}^n$ ($y_i$- $\hat y$) $^2$** 
- 回归平方和`SSR`：**SSR = $\sum_{i=1}^n$ ($\hat y$ - $\overline y$) $^2$** 

有个结论：`SST = SSE + SSR` 

拟合优度：**R$^2$ = $\frac {SSR}{SST}$ = 1 - $\frac {SSE}{SST}$  （0<R$^2$<1）**  

由上式可知，**R$^2$越接近1，说明误差平方和越接近0，拟合效果越好**。

**tips**：

1. 使用R$^2$ 来判断拟合的好坏的**前提**是拟合函数要为线性函数。
2. 非线性函数比较拟合的好坏时直接看**SSE**即可。

**线性函数**的介绍：

线性函数有两种解释

1. 一种是对**变量线性**：即变量是线性的，比如`a*x+b` 变量x是线性的。
2. 一种是对**参数线性**：即参数是线性的，比如`a*x^2+b` 参数a，b是线性的。

可能有些小伙伴不太清除线性的意思，这里啰嗦一句。

> 线性就是在函数中，参数仅以一次方出现，且不能乘以或除以其他任何的参数，并不能出现参数的复合函数形式

比如 y = $a_1$+$a_2$x+$a_3$x$^2$ 、y = e$^{a_1+a_2x}$ 都是线性函数。注意：我们这里讲的都是参数线性。

在`matlab`中，有个很好用的拟合工具箱，专门用来处理拟合操作。

![image-20200626213134996](数学建模.assets/image-20200626213134996.png)

也可以直接在命令行输入`cftool` 打开拟合工具箱。

具体功能如下：

![image-20200626213325192](数学建模.assets/image-20200626213325192.png)

工具箱提供的拟合类型有：

1. Custom Equations：用户自定义的函数类型
2. Exponential：指数逼近，有2种类型， a\*exp(b\*x) 、 a\*exp(b\*x) + c\*exp(d\*x)
3. Fourier：傅立叶逼近，有7种类型，基础型是 a0 + a1\*cos(x\*w) + b1\*sin(x\*w)
4. Gaussian：高斯逼近，有8种类型，基础型是 a1\*exp(-((x-b1)/c1)^2)*
5. Interpolant：插值逼近，有4种类型，linear、nearest neighbor、cubic spline、shape-preserving
6. Polynomial：多项式逼近，有9种类型，linear ~、quadratic ~、cubic ~、4-9th degree ~
7. Power：幂逼近，有2种类型，a\*x^b 、a\*x^b + c
8. Rational：有理数逼近，分子、分母共有的类型是linear ~、quadratic ~、cubic ~、4-5th degree ~；此外，分子还包括constant型
9. Smoothing Spline：平滑逼近
10. Sum of Sin Functions：正弦曲线逼近，有8种类型，基础型是 a1\*sin(b1\*x + c1)
11. Weibull：只有一种，a\*b\*x^(b-1)\*exp(-a*x^b)

**tips**：

- 如果选**Custom Equations**时，拟合曲线与样本点距离较远，可以适当点击`Fit options` 按钮的`StartPoint` 

# 5. 相关系数

> 相关系数是用来衡量两个变量之间的相关性的大小，根据数据满足的不同条件，我们要选择不同的相关系数进行计算和分析，一般用的比较多的是**斯皮尔曼**相关系数。

虽然相关系数可以反映两个数据的相关性，但是大家往往更关注的是显著性（假设检验）。

首先，在算显著性之前我们最好给出数据的描述性统计，例如算出每组数据的最小、最大、中位数、均值、偏度、风度、标准差等，然后可以利用`spass`做个统计。

```matlab
MIN = min(Test); % 每一列的最小值
MAX = max(Test); % 每一列的最大值
MEAN = mean(Test); % 每一列的均值
MEDIAN = median(Test); %每一列的中位数
SKEWNESS = skewness(Test); %每一列的偏度
KURTOSIS = kurtosis(Test); %每一列的峰度
STD = std(Test); % 每一列的标准差
RESULT = [MIN;MAX;MEAN;MEDIAN;SKEWNESS;KURTOSIS;STD] 
%将这些统计量放到一个矩阵中表示
```

## 5.1 斯皮尔曼相关系数

斯皮尔曼相关系数用来描述定序数据最为合适。

**定序数据**是指仅仅反映观测对象等级、顺序关系的数据，是由定序尺度计量形成的，表现为类别，可以进行排序。

### 5.1.1 斯皮尔曼定义一

- 定义：X和Y为两组数据，其斯皮尔曼（等级）相关系数：
  ![spearman相关系数](https://img-blog.csdnimg.cn/20191028164930847.png#pic_center)
  其中，di为Xi和Yi之间的等级差。可以证明：rs位于-1和1之间。
- 等级差
  一个数的等级，就是将它所在的一列按照从小到大排序后，这个数所在的位置。
  ![等级差](数学建模.assets/20191028183553454.png)

根据公式计算可得：X和Y的斯皮尔曼相关系数 rs = 0.875

### 5.1.2 斯皮尔曼定义二

另一种斯皮尔曼相关系数被定义成**等级之间的皮尔逊相关系数**。值得注意的是，**MATLAB的corr函数使用的是该定义下的计算方式**。

corr函数的两种用法：

1. **corr(X , Y , 'type' , 'Spearman')**  计算X跟Y的斯皮尔曼相关系数，X和Y必须是列向量
2. **corr(X , 'type' , 'Spearman')** 计算X矩阵的各列之间的斯皮尔曼相关系数

```matlab
% 求两组数据的斯皮尔曼
X = [3 8 4 7 2]' % 一定要是列向量哦，一撇'表示求转置
Y = [5 10 9 10 6]'
r = corr(X , Y , 'type' , 'Spearman')  % 0.8721
```

### 5.1.3 对斯皮尔曼相关系数进行假设检验

1. 当`n<=30`时，直接查临界值表即可。（$H_0$：$r_s=0$   $H_1:r_s ≠0$）
   
   使用得出的斯皮尔曼相关系数 r 与对应的临界值$r_0$进行比较，只有$r ≥ r_0$时 才会接受$H_0$ 
   
   ![斯皮尔曼等级相关的临界值](数学建模.assets/20191028194952788-1593337545099.png)

2. 大样本情况下，
   
   统计量满足 $r_s \sqrt {n-1} $ **~** $N(0,1) $
   
   $H_0$：$r_s=0$   $H_1:r_s ≠0$ 
   
   我们计算 R = $r_s \sqrt {n-1}$ ，并求 R对应的p值P，将P与0.05比较。
   
   P≥0.05，接受$H_0$ 
   
   在`matlab`中**`corr`**函数可以直接得出相关系数跟p值
   
   ```matlab
   % R为相关系数  P为p值
   [R,P]=corr(Test, 'type' , 'Spearman')
   ```

**tips：$r_s = 0$ 表示这两组数据无明显相关性。**

**在建模中，使用斯皮尔曼相关系数计算时，可以使用SPSS列出相关性的表格（分析->相关->双变量）** 

## 5.2 皮尔逊相关系数

因为使用皮尔逊相关系数的前提有三点，所以一般不使用 **皮尔逊**相关系数。

前提：

- 两个变量之间是**线性**关系，且是连续数据。
- 两个变量的总体是**正态分布**，或接近正态的单峰分布。
- 两个变量的观测值是成对的，且每对观测值之间**相互独立**。

在给出不使用皮尔逊相关系数计算的时候，最好可以给出`矩阵散点图`（图形 ‐ 旧对话框 ‐ 散点图/点图 ‐ 矩阵散点图）来说明。

复习一下《概率论与数理统计》中的均值与协方差的公式：

如果给了两组数据X:{$X_1,X_2,...,X_n$}和Y:{$Y_1,Y_2,...,Y_n$}是总体数据，那么

总体均值 **E(X) =** **$\frac {1}{n}$ $\sum_{i=1}^n X_i$**， **E(Y)** = **$\frac {1}{n}$ $\sum_{i=1}^n Y_i$**

总体协方差：**Cov(X,Y) =** **$\frac {1}{n}$ $\sum_{i=1}^n (X_i-E(X))(Y_i-E(Y))$**

协方差可以反映出两组数据的相关性。但是协方差的大小与两组数据的梁刚有关，因此不适合作比较。

而 皮尔逊相关系数则可以看成是排除了量纲的影响，即将X,Y标准化后的协方差。

`matlab`中的函数**`corrcoef`**可以直接计算皮尔逊相关系数

```matlab
% 返回 A 的相关系数的矩阵，其中 A 的列表示随机变量（指标），行表示观测值（样本）。
R = corrcoef(A)  

% 返回两个随机变量 A 和 B （两个向量）之间的系数
R = corrcoef(A,B)
```

### 5.2.1 对皮尔逊相关系数进行假设检验

# 6.典型相关分析

前面提到的斯皮尔曼跟皮尔逊都是研究单单两个指标之间的内在联系（一元）。

而**典型相关分析**（Canonical Correlation analysis）研究**两组**变量（每组变量中都可能有多个指标）之间相关关系的一种**多元**统计方法。它能够揭示出两组变量之间的内在联系。它的思想在于**降维**。

需要注意的是，这两组变量都要符合正态分布，**题目中如果没说符不符合，我们可以假设它符合**。

使用步骤：

1. 在每组变量中找出变量的线性组合，使得两组的线性组合之间具有**最大**的相关系数；
2. 如果第一次求出的相关系数不满足条件，则需要选取过和前面次数都不相关的线性组合；
3. **如此继续下去**，直到两组变量之间的相关性被提取完毕为止或已经可以满足条件。

**tips**：被选出的线性组合配对称为**`典型变量`**，它们的相关系数称为**`典型相关系数`**。典型相关系数度量了这两组变量之间联系的强度。

比如身体性能（身高、腰围、体重）与体育性能（引体向上、仰卧起坐、体前屈）之间的关系，此时如果直接对这些变量两两进行分析，那么得到的结果是片面的。那要如何做呢?

我们可以把身体性能的多个指标通过简单的线性组合 形成一个代表身体性能的`典型变量`，体育性能亦如此，这样我们就可以将6个指标降到2个指标（这就是降维的思想）。

假设我们把第一组的身高、腰围、体重分别记为$X_1^{(1)}、X_2^{(1)}、X_3^{(1)}$ ，则这三个指标通过线性组合形成的`典型变量` 记为 $U_i = a_1^i X_1^{(1)} + a_2^i X_2^{(1)} + a_3^i X_3^{(1)}$ ，**i代表第几次**。用矩阵表示为：$U_i = {a^i}^` X^{(1)}$  变量a的转置矩阵乘以变量$X_i$ 

同理把第二组的引体向上、仰卧起坐、体前屈分别记为 $X_1^{(2)}、X_2^{(2)}、X_3^{(2)}$ ，这三个指标形成的`典型变量` 记为$V_i = b_1^i X_1^{(2)} + b_2^i X_2^{(2)} + b_3^i X_3^{(2)}$ 。

**tips：$U_iV_i$叫做典型变量； $a_1a_2a_3, b_1b_2b_3$ 称为典型相关系数**

因为相关系数与量纲无关，所以需要加上一个条件：$var(U_i)$ = $var(V_i)$ = 1，两者的方差要等于1。

那如何要保证每一次的线性组合都不相关呢？$cov(U_{i-1},U_i)$ = $cov(V_{i-1},V_i)$ = 0。

知道了上面的一些定义，那如何求典型相关系数呢？

在`SPSS 24`版本以前，我们需要自己编写代码来求解，在24以后，`SPSS` 提供了直接求解典型相关分析的功能。

> 如果你的SPSS在24以上却没有典型相关分析功能，则可能是因为你在安装SPSS的时候修改了默认安装路径，卸载重装使用默认路径即可。

现在来讲解此功能。

第一步，导入数据。

![image-20200629212837819](数学建模.assets/image-20200629212837819.png)

第二步，检验数据的类型（全部变成标度）

![image-20200629212917569](数学建模.assets/image-20200629212917569.png)

第三步，选择使用典型相关分析

![image-20200629213021374](数学建模.assets/image-20200629213021374.png)

第四步：将数据移动到对应的集合

![image-20200629213043862](数学建模.assets/image-20200629213043862.png)

第五步：对结果进行分析

![image-20200629214805917](数学建模.assets/image-20200629214805917.png)该表格的显著性（p值）如果**小于**0.05（0.1）表示在95%（90%）的置信水平下拒绝原假设，即认为这两组变量有关，其相关性如第一列所示。

那么上图表格说明了进行了三次线性组合，而这三次的两组变量都有关，而且相关性分别为0.995、0.953、0.637。

![image-20200629215203696](数学建模.assets/image-20200629215203696.png)

该表格说明了在集合1中第一次求得的典型相关系数为0.149、0.977、-0.052，相对应的本次的典型变量$u_1 = 0.149*低学历+0.977*高学历-0.052*互联网$ 。其他次也是同样的求法。

![image-20200629220616867](数学建模.assets/image-20200629220616867.png)

同理也可求得集合二的典型相关系数跟典型变量，以第一次的为例：$V_1 = 0.858*艺术家+0.019*发行+0.145*行内主管$。

<u>接着两个表格是非标准化的，我们一般不使用（因为使用标准化的更好）。</u>

![image-20200629220743758](数学建模.assets/image-20200629220743758.png)

典型载荷是指原始变量与典型变量之间的相关性分析，比如集合1的典型载荷的第一典型变量与低学历的相关系数为0.333，与高学历的相关系数为0.993，与互联网的相关系数为0.383。从另一方面说明集合1的第一对典型变量与低学历、高学历、互联网都成正相关。其中高学历的相关性最强。第一对典型变量主要反映了高学历观众对电视节目的打分。

# 7. 回归分析

**回归分析**是数据分析中最基础也是最重要的分析工具，绝大多数的数据分析问题，都可以使用回归的思想来解决。

回归分析的**任务**就是通过研究**自变量X**和**因变量Y**的**相关关系**，尝试去解释Y的形成机制，进而达到通过X去预测Y的目的。

使用回归的**条件**：因变量要大于自变量。

`XY`也有另外一种叫法：把`X`称为**解释变量**，`Y`称为**被解释变量**。

需要注意的是：`相关关系≠因果关系`。

常见的回归分析有五类：**线性回归、0‐1回归、定序回归、计数回归和生存回归**，其划分的依据是因变量Y的类型。

回归分析要完成的三个**使命**：

1. **识别重要变量**：判断哪些X变量是真的与Y相关，这一步也叫作**变量选择**。
2. **判断相关性的方向**：去除了第一步的不相关变量后，判断留下的变量与Y的相关关系的正负。
3. **估计权重（回归系数）**：在确定了重要的X变量的前提下，我们还想给不同X赋予不同的权重，也就是不同的回归系数，进而我们可以知道不同变量之间的相对重要性。

## 7.1 回归类型与数据类型

回归类型 

在实际应用中，`Y`常常是我们需要研究的那个核心变量。

1. 经济学家研究经济增长的决定因素，那么Y可以选取为GDP增长率**（Y为连续数值型变量）**。
2. P2P公司要研究借款人是否能按时还款，那么Y可以设计成一个二值变量，Y=0时代表可以还款，Y=1时代表不能还款**（Y为0‐1型变量）**。
3. 消费者调查得到的数据Y（1表示非常不喜欢，2表示有点不喜欢，3表示一般般，4表示有点喜欢，5表示非常喜欢）**（Y为定序变量）**。
4. 管理学中RFM模型：F代表一定时间内，客户到访的次数Y，次数其实就是一个非负的整数。**（Y为计数变量）**。
5. 研究产品寿命、企业寿命甚至是人的寿命Y（这种数据往往不能精确的观测，例如现在要研究吸烟对于寿命的影响，如果选取的样本中老王60岁，现在还活的非常好，我们不可能等到他去世了再做研究，那怎么办呢？直接记他的寿命为60+，那这种数据就是截断的数据）**（Y为生存变量）**

| 类型    | 模型            | Y的特点      | 例子        |
| ----- |:-------------:|:---------:|:---------:|
| 线性回归  | OLS、GLS（最小二乘） | 连续数值型变量   | GDP、产量、收入 |
| 0-1回归 | logistic回归    | 二值变量（0‐1） | 是否违约、是否得病 |
| 定序回归  | probit定序回归    | 定序变量      | 等级评定（优良差） |
| 计数回归  | 泊松回归（泊松分布）    | 计数变量      | 每分钟车流量    |
| 生存回归  | Cox等比例风险回归    | 生存变量      | 企业、产品的寿命  |

数据的分类

1. **横截面数据**：在某一时间段收集的不同对象的数据。
   
   - 例如：
     
     （1）我们自己发放问卷得到的数据
     
     （2）全国各省份2018年GDP的数据
     
     （3）大一新生今年体测的得到的数据

2. **时间序列数据**：对同一对象在不同时间连续观察所取得的数据。
   
   - 例如：
     
     （1）从出生到现在，你体重的数据（每年生日称一次)。 
     
     （2）中国历年来GDP的数据。
     
     （3）在某地方每隔一小时测得的温度数据。

3. **面板数据**：横截面数据与时间序列数据综合起来的一种数据资源。
   
   - 例如：2008‐2018年，我国各省份GDP的数据。

不同数据类型的处理方法

| 数据类型   | 常见建模方法                    |
|:------:|:-------------------------:|
| 横截面数据  | 多元线性回归                    |
| 时间序列数据 | 移动平均、指数平滑、ARIMA、GARCH、VAR |
| 面板数据   | 固定效应和随机效应、静态面板和动态面板       |

## 7.2 多元线性回归

一元线性回归跟多元线性回归的区别：一元线性回归只有一个自变量x，而多元线性有多个。

**一元线性回归模型**
 假设x是自变量，y是因变量，且满足如下线性关系: **$y_i = β_0+β_1x_i+μ_i$** 
 β0和β1为回归系数，β0的数值意义我们一般不考虑，μ为无法观测的且满足一定条件的扰动项。

所谓线性，拟合那章说过，这里不再赘述，比如下面的函数都是线性的：

$y_i=β_0+β_1lnx_i+μ_i$ 

$lny_i=β_0+β_1lnx_i+μ_i$ 

$y_i=β_0+β_1x_{1i}+β_2x_{2i}+σx_{1i}x_{2i}+μ_i$ 

线性回归又分为两种：

1. **解释**性线性回归：$R^2$不需要太大，能解释就行。
2. **预测**性线性回归：$R^2$越接近于一越好，例如拟合操作。

**内生性跟外生性** 

如果满足误差项𝝁和所有的自变量`x`均不相关，则称该回归模型具有**`外生性`**。（如果与其中一个相关，则存在**`内生性`**，内生性会导致回归系数估计的不准确：不满足无偏和一致性）

**核心解释变量和控制变量** 

很明显，完全做到外生性是不现实的。那么我们就需要对其进行弱化。

所谓弱化就是将所有的解释变量**x**分为**`核心解释变量`**与**`控制变量`**两类，**在实际应用中，我们只要保证核心解释变量与𝝁不相关即可** 

- `核心解释变量`：我们最感兴趣的变量，因此我们特别希望得到对其系数的一致估计（当样本容量无限增大时，收敛于待估计参数的真值 ）。
- `控制变量`：我们可能对于这些变量本身并无太大兴趣；而之所以把它们也放入回归方程，主要是为了 “控制住” 那些对被解释变量有影响的遗漏因素。

**四类模型回归系数的解释** 

1. `一元线性回归`：y=a+bx+μ，x每增加1个单位，y平均变化b个单位。
2. `双对数模型`：lny=a+blnx+μ，x每增加1%，y平均变化b%
3. `半对数模型`：y=a+blnx+μ，x每增加1%，y平均变化b/100个单位；
4. `半对数模型`：lny=a+bx+μ，x每增加1个单位，y平均变化（100b）%

**取对数意味着原被解释变量对解释变量的弹性，即百分比的变化而不是数值的变化**；

目前，对于什么时候取对数还没有固定的规则，但是有一些经验法则：

1. 与市场价值相关的，例如，价格、销售额、工资等都可以取对数；
2. 以年度量的变量，如受教育年限、工作经历等通常不取对数；
3. 比例变量，如失业率、参与率等，两者均可；
4. 变量取值必须是非负数，如果包含0，则可以对y取对数ln(1+y);

**取对数的好处：**（1）减弱数据的异方差性（2）如果变量本身不符合正态分布，取

了对数后可能渐近服从正态分布（3）模型形式的需要，让模型具有经济学意义。

**求解多元线性回归**：

![image-20200705102050685](数学建模.assets/image-20200705102050685.png)

![image-20200705102115519](数学建模.assets/image-20200705102115519.png)

然后统计好**调整后的$R^2$** 、**显著性（P值）**、**标准化系数**。

![image-20200705113054403](数学建模.assets/image-20200705113054403.png)

![image-20200705113122550](数学建模.assets/image-20200705113122550.png)

![image-20200705120735436](数学建模.assets/image-20200705120735436.png)

符合置信区间前提下，标准化系数绝对值越大，对因变量的影响就越大。

**补充：关于拟合优度和调整后的拟合优度：** 

我们引入的自变量越多，拟合优度会变大。但我们倾向于使用调整后的拟合优度，如果新引入的自变量对SSE的减少程度特别少，那么调整后的拟合优度反而会减小。

## 7.3 补充

在之前的回归分析中，我们都默认了扰动项是**球型扰动项**（满足“同方差”和“无自相关”两个条件）。

而**横截面数据**容易出现异方差的问题；**时间序列数据**容易出现自相关的问题。

如果<u>扰动项</u>存在<u>异方差</u>：

（1）OLS估计出来的回归系数是无偏、一致的。

（2）假设检验无法使用（构造的统计量失效了）。

（3）OLS估计量不再是最优线性无偏估计量（BLUE）。

解决异方差的方法：

（1）使用OLS + 稳健的标准误（大多数情况时用此方法）

（2）广义最小二乘估计法GLS（方差较小的数据给予更大的权重）

可以先自己对异常数据进行删除，或者给**数据加ln**（推荐）。

<u>在使用SPSS求解多元线性回归时，应该先对数据进行预处理、对数据进行正态线性检验、异方差检验、自相关检验以及共线性检验。</u>

### 7.3.1 数据预处理（创建虚拟变量）

自变量中有**`定性变量`**，例如性别、地域。

例如，工资 $y_i = β_0+σ_0sex_i+β_1x_1+...+β_nx_n$ 

令 $sex_i$=1表示女性；$sex_i$=0表示男性；（取0的为对照组）

那么$σ_0$可解释为：在其他自变量给定的情况下，女性的平均工资 大于/小于 男性的平均工资

地域借款是否成功$success_i = α+\sum{β_n×Province_n} +λ×Controls_i+μ$ 

假如有21个自变量，我们需要拿一个出来作为对照组（比如拿广东），此时n=20

比如，$province_1$表示江苏，当且仅当地域为江苏时，$province_1$取1，其他$province_n$都取0

这么做是为了避免多重共线性。

含有**`交互项`**的自变量

比如 房价$price=β_0+β_1area+β_2rNum+β_3area·rNum+μ$ 

若 $β_3>0$ 则意味着住房面积越大，增加一间卧室导致房价增长。换言之，住房的平方英尺数与卧室的间数之间存在交互效应。

### 7.3.2 正态线性检验

做回归分析之前，变量必须满足正态性，**一般在建模中都是假设变量满足正态性**。

我们也可以使用SPSS来检验数据符不符合正态性。

![image-20200706223003439](数学建模.assets/image-20200706223003439.png)

![image-20200706223038473](数学建模.assets/image-20200706223038473.png)

![image-20200706223151761](数学建模.assets/image-20200706223151761.png)

### 7.3.3 异方差检验

第一种方式：

![image-20200706223309484](数学建模.assets/image-20200706223309484.png)

![image-20200706223352660](数学建模.assets/image-20200706223352660.png)

![image-20200706223957179](数学建模.assets/image-20200706223957179.png)

![image-20200706223947539](数学建模.assets/image-20200706223947539.png)

![image-20200706224406760](数学建模.assets/image-20200706224406760.png)

第二种方式：（斯皮尔曼）

（1）回归计算时，在回归主对话框中单击`[保存]`按钮，选择`[残差]`中的`[未标准化残差]`选项，单击`[继续]`返回主对话框。输出结果的同时，将把`残差`保存为---`新变量res_1`。

（2）计算残差的平方。选择 `[转换]` => `[计算变量]`，在显示的对话框中输入残差平方的变量名（如e2）和计算残差平方的表达式(如res_1 **2 )。单击`[OK]`后将产生一个新变量。

![image-20200706224728152](数学建模.assets/image-20200706224728152.png)

（3）

![image-20200706224853575](数学建模.assets/image-20200706224853575.png)

![image-20200706225040565](数学建模.assets/image-20200706225040565.png)

![image-20200706225353817](数学建模.assets/image-20200706225353817.png)

### 7.3.4 共线性检验

![image-20200706230054313](数学建模.assets/image-20200706230054313.png)

![image-20200706230246985](数学建模.assets/image-20200706230246985.png)

**VIF方差膨胀因子**

共线性即多重共线性，是指线性回归模型中的解释变量之间由于存在精确[相关关系](https://baike.baidu.com/item/相关关系/9227098)或高度相关关系而使模型估计失真或难以估计准确

如果发现存在多重共线性，可以采取以下**处理方法**。
（1）如果不关心具体的回归系数，而只关心整个方程预测被解释变量的能力，则通常可以不必理会多重共线性（假设你的整个方程是显著的）.这是因为，多重共线性的主要后果是使得对单个变量的贡献估计不准，但所有变量的整体效应仍可以较准确地估计。
（2）如果关心具体的回归系数，但多重共线性并不影响所关心变量的显著性，那么也可以不必理会。即使在有方差膨胀的情况下，这些系数依然显著；如果没有多重共线性，则只会更加显著。
（3）如果多重共线性影响到所关心变量的显著性，则需要增大样本容量，剔除导致严重共线性的变量（不要轻易删除哦，因为可能会有内生性的影响），或对模型设定进行修改

# 8. 图论

**Prim**跟**Kruskal**是用来计算`最小生成树`的算法，计算的是整一棵树最小的权值总和。比如给n个小村庄修路，怎样铺路才能使得每个村庄都通路并且开销最小。
**Dijkastra**是用来计算`单源最短路径`，即源点到任意点的最短路径。比如，A村庄到B村庄，怎么走最短。

**Floyd**是用于计算`多源点最短路径`。例如计算任意两个城市之间的最短路程。

**Bellman-Ford**也是用于计算`单源最短路径`，但它可以解决`负权边`，而`Dijkastra`无能为力。

应该说除了Bellman-Ford，其他图都不法处理负权边，但Bellman-Ford无法处理`负权回路`。

什么是`负权回路`？顾名思义，就是回路中的边都是负数。

**tips：无向图是一个特殊的有向图，只要无向图中有一个边是负数就存在负权回路**

***

无向图

```matlab
% 函数graph(s,t)：可在 s 和 t 中的对应节点之间创建边，并生成一个图
G1 = graph(s1, t1);
plot(G1)
% 函数graph(s,t,w)：可在 s 和 t 中的对应节点之间以w的权重创建边，并生成一个图
G2 = graph(s2, t2, w);
plot(G2, 'linewidth', 2)  % 设置线的宽度
% 下面的命令是在画图后不显示坐标
set( gca, 'XTick', [], 'YTick', [] ); 
```

**要做出有向图，只需要将graph改为digraph就行了**

***

**计算最短路径** 

```matlab
[P,d] = shortestpath(G,start,end [,'Method',algorithm] )
```

**输入参数：** 

（1）G ‐ 输入图（graph 对象 | digraph 对象）

（2）start 起始的节点，大于0

（3）end 目标的节点

（4）[,‘Method’,algorithm]是可选的参数，表示计算最短路径的算法。一般我们不用手动设置，默认使用的是“auto”。

**输出参数：** 

（1）P – 最短路径经过的节点

（2）d – 最短距离

***

```matlab
% 在图中高亮我们的最短路径
myplot = plot(G, 'EdgeLabel', G.Edges.Weight, 'linewidth', 2);  %首先将图赋给一个变量
highlight(myplot, P, 'EdgeColor', 'r')   %对这个变量即我们刚刚绘制的图形进行高亮处理（给边加上r红色）
```

```matlab
% 求出任意两点的最短路径矩阵
D = distances(G)   % 注意：该函数matlab2015b之后才有
D(1,2)  % 1 -> 2的最短路径
D(9,4)  % 9 -> 4的最短路径
```

```matlab
% 找出给定范围内的所有点  [nodeIDs,dist] = nearest(G,s,d)
% 返回图形 G 中与节点 s 的距离在 d 之内的所有节点
[nodeIDs,dist] = nearest(G, 2, 10)   %注意：该函数matlab2016a之后才有
```

**`nodeIDs`**符合条件的节点，**`dist`**这些节点与s的最短距离。

# 9. 分类模型

对于**二分类/多分类**模型，我们都可以使用`逻辑回归`(logistic regression)和`Fisher线性判别分析`两种分类算法来求解。

什么是二分类呢？根据变量的多个属性值，判断该变量的种类（只有两个）。

## 9.1 线性回归求解二分类

首先建立线性模型， $y=β_0+β_1x+β_2x+β_3x+...+μ_i$ 

要使y的范围在[0,1]之间，我们令右边为X，然后可以对X取两个回归函数的其中一个：

1. **probit回归**：取为标准正态分布的累积密度函数（cdf）
   
   y = F(X) = $\int_0^X \frac {1}{\sqrt{2π}}e^{- \frac {t^2}{2}} dt$ 

2. **logistic回归**：取为 Sigmoid函数。(**常用**)
   
   y = F(X) = $\frac {e^X}{1+e^X} dt$   

如果$\hat y$ ≥ 0.5，则认为其预测的y=1。否则则认为其预测的y=0。

### 9.1.1 使用SPSS求解

第一步需要对因变量创建虚拟变量，并进行筛选。**虚拟变量就是可以表示定序的数据，比如1、2、3** 

![image-20200709182221858](数学建模.assets/image-20200709182221858.png)

![image-20200709182247581](数学建模.assets/image-20200709182247581.png)

如果有**分类变量**，可以放到这里，就不用手动将其变成虚拟变量了。

![image-20200709182509561](数学建模.assets/image-20200709182509561.png)

![image-20200709182310593](数学建模.assets/image-20200709182310593.png)

### 9.1.2 分析结果

![image-20200709183148811](数学建模.assets/image-20200709183148811.png)

19个苹果样本中，预测出来为苹果的有14个，预测出来的正确率为73.7%;

19个橙子样本中，预测出来为橙子的有15个，预测出来的正确率为78.9%;

对于整个样本，逻辑回归的预测成功率为76.3%。

![image-20200709183305898](数学建模.assets/image-20200709183305898.png)

B为$x_i$的参数。显著性为P值，小于0.05就显著。

回到SPSS中，会发现新增了两列。

![image-20200709192028268](数学建模.assets/image-20200709192028268.png)

**预测结果较差怎么办**？可在logistic回归模型中加入**平方项**、**交互项**等

虽然加入平方项跟交互项可以提高预测效果。但会出现**过拟合现象**。

如何确定合适的模型？把数据分为**训练组**和**测试组**，用**训练组**的数据来估计出模型，再用**测试组**的数据来进行测试。（训练组和测试组的比例一般设置为80%和20%）

注意：为了消除偶然性的影响，可以多重复训练跟测试，最终对每个模型求一个平均的准确率，这个步骤称为**交叉验证**。

## 9.2 Fisher线性判别分析

`LDA`(Linear Discriminant Analysis)是一种经典的线性判别方法，又称`Fisher判别分析`。

该方法思想比较简单：给定训练集样例，设法将样例投影到一维的直线上，使得同类样例的投影点尽可能接近和密集，异类投影点尽可能远离。

![image-20200709194315645](数学建模.assets/image-20200709194315645.png)

![image-20200709194425830](数学建模.assets/image-20200709194425830.png)

![image-20200709194500321](数学建模.assets/image-20200709194500321.png)

![image-20200709194612254](数学建模.assets/image-20200709194612254.png)

## 9.3 Fisher判别分析用于多分类

![image-20200709194703325](数学建模.assets/image-20200709194703325.png)

**注意：多分类时，SPSS不能自动帮我们生成虚拟变量，我们可以在 EXCEL：表中使用“替换"功能来快速生成虚拟变量** 。

# 10.聚类模型

所谓的聚类，就是将样本划分为由类似的对象组成的多个类的过程。聚类后，我们可以更加准确的在每个类中单独使用统计模型进行估计、分析或预测；也可以探究不同类之间的相关性和主要差异。

聚类跟分类的区别：**分类是已知类别的，而聚类未知**。

## 10.1 K-means聚类跟K-means++聚类

`K-means`聚类的算法流程：

![image-20200711155145608](数学建模.assets/image-20200711155145608.png)

![image-20200711155030855](数学建模.assets/image-20200711155030855.png)

优点：

（1）算法简单、快速。

（2）对处理大数据集，该算法是相对高效率的。

缺点：

（1）要求用户必须事先给出要生成的簇的数目`K`。 

**（2）对初值敏感。** 

**（3）对于孤立点数据敏感。**  

***

**`K‐means++`算法可解决第2、第3这两个缺点**

`k-means++`算法选择初始聚类中心的基本原则是：**初始的聚类中心之间的相互距离要尽可能的远。** 

![image-20200711155703134](数学建模.assets/image-20200711155703134.png)

1）聚类的个数`K`值怎么定？

答：分几类主要取决于个人的经验与感觉，通常的做法是多尝试几个K值，看分成几类的结果更好解释，更符合分析目的等。

2）数据的量纲不一致怎么办？

答：如果数据的量纲不一样，那么算距离时就没有意义。可以对数据进行标准化，标准化后的数据$z=\frac {x_i-\overline x}{σ_x}$ （减去均值后再除以标准差）,公式不唯一。

***

SPSS软件使用`K‐means++`算法。

![image-20200711155940855](数学建模.assets/image-20200711155940855.png)

## 10.2 系统（层次）聚类

**系统聚类**的合并算法是通过计算两类数据点间的距离，对最为接近的两类数据点进行组合，并反复迭代这一过程，直到将所有数据点合成一类，并生成聚类谱系图。

![image-20200711162144575](数学建模.assets/image-20200711162144575.png)

常用计算距离公式：(p个点，样品i与样品j)

- **绝对值距离**：d($x_i$,$x_j$) = $\sum_{k=1}^{p} |x_{ik}-x_{jk}|$ ，【||表示距离，不是绝对值】
- **欧氏距离**：d($x_i$,$x_j$) = $\sqrt {(x_{ik}-x_{jk})^2}$ ，也就是距离公式

类与类之间的常用距离：

假设$G_p$和$G_q$是两个类，D($G_p,G_q$)表示两个类之间的距离，$x_i∈G_p，x_j∈G_q$ ,d($x_i,x_j$)是两个样品的距离。

- **最短距离**：D($G_p,G_q$) = min d($x_i,x_j$)
- **最长距离:** D($G_p,G_q$) = max d($x_i,x_j$)
- **组间平均连接法:** D($G_p,G_q$) = **$\frac {d_1+d_2 +d3+...+d_n}{n}$**  两个类所有的点两两的距离之和除以距离数
- **组内平均连接法**：D($G_p,G_q$) = **$\frac {d_1+d_2 +d3+...+d_n}{n}$**  与组间相比，算上了本类所有点之间的两两距离
- **重心法:** D($G_p,G_q$) = d($\overline x_p,\overline x_q$) ，$x_p,x_q$为两个类的重心。

***

SPSS软件使用聚类分析

![image-20200711172902319](数学建模学习笔记.assets/image-20200711172902319.png)

![image-20200711173117393](数学建模学习笔记.assets/image-20200711173117393.png)

系统聚类最终会形成一个类，需要自行根据谱系图来选取`K` 

![image-20200711164947509](数学建模.assets/image-20200711164947509.png).

可以画出**聚合系数**的折线图(横坐标为聚类的类别数K，纵坐标为聚合系数j)，拐角点就是K值，当然可以根据实际情况来选择。

![image-20200711174931003](数学建模学习笔记.assets/image-20200711174931003.png)

根据图来进行解释：

(1)根据聚合系数折线图可知，当类别数为5时，折线的下降趋势趋缓，故可将类别数设定为5.

(2)从图中可以看出， K值从1到5时，畸变程度变化最大。超过5以后，畸变程度变化显著降低。因此肘部就是 K=5，故可将类别数设定为5.（当然，K=3也可以解释）

***

确定K后保存聚类结果并画图，当然只有两个或三个变量的时候才可以画图

![image-20200711174241225](数学建模学习笔记.assets/image-20200711174241225.png)

**如果指标很多，画不了图，可以考虑使用主成分分析来进行降维。** 

## 10.3 DBSCAN算法

前面两种算法都是基于距离的。而DBSCAN一种基于**密度**的聚类方法，聚类前不需要预先指定聚类的个数，生成的簇的个数不定（和数据有关）。**能有效处理异常数据**。

**基本概念**：

DBSCAN算法将数据点分为**三类**：

- **核心点**：在半径`Eps`内含有不少于`MinPts`数目的点
- **边界点**：在半径Eps内点的数量小于MinPts，但是落在核心点的邻域内
- **噪音点**：既不是核心点也不是边界点的点

![image-20200711180729221](数学建模学习笔记.assets/image-20200711180729221.png)

**边界点跟核心点都属于同一个类，而噪音点是异常点。**

**优点：** 

1. 基于密度定义，能处理任意形状和大小的簇；
2. 可在聚类的同时发现异常点；
3. 与K-means比较起来，不需要输入要划分的聚类个数。

**缺点：**

1. 对输入参数ε和Minpts敏感，确定参数困难；
2. 由于DBSCAN算法中，变量ε和Minpts是全局唯一的，当聚类的密度不均匀时，聚类距离相差很大时，聚类质量差；
3. 当数据量大时，计算密度单元的计算复杂度大。

**建议：**

只有两个指标，且你做出散点图后发现数据表现得很有 图形像，这时候你再用`DBSCAN`进行聚类。

其他情况下，全部使用**系统聚类**。K‐means也可以用，不过用了的话你论文上可写的东西比较少

# 11. 时间序列分析

时间序列分析大致可分成三大部分，分别是**描述过去**、**分析规律**和**预测未来（三种方法）**。

**时间序列**也称**动态序列**，是指将某种现象的指标数值按照时间顺序排列而成的数值序列。

时间序列由两个组成要素构成：

1. **时间要素**；年、季度、月、周、日、小时、分钟、秒。
2. **数值要素**。

时间序列根据时间和数值性质的不同，可以分为**时期时间序列**和**时点时间序列**。

**`时期序列`**中，数值要素反映现象在一定**时期**内发展的结果；比如，中国历年来GDP的数据。

**`时点序列`**中，数值要素反映现象在一定**时点上的瞬间水平**；比如，从出生到现在，你的体重的数据。

区别他们的最主要方法：**时期序列可相加，时点序列不可相加（相加后无意义）** 

一般情况下，时间序列的数值变化规律有以下四种：

- 长期变动趋势`T` 
- 季节变动规律`S`：指由于季节的转变使得指标数值发生周期性变动。不能以**年**作单位。
- 周期变动规律`C`：周期变动通常以若干**年**为周期。经常跟经济周期挂钩。
- 不规则变动`I`：就是随机扰动项

**tips：**数据具有周期性时，时间序列可以分解成以上四类变化形式的`叠加`或`乘积`。

叠加模型：`Y = T + S + C + I` 

乘积模型：`Y = T * S * C * I` 

什么时候使用叠加模型，什么时候使用乘积模型？

如果随着时间的推移，序列的**季节波动**变得**变大或变小**，建议使用**乘积模型**；反之，如果时间序列图的**波动**保持**恒定**，则可以直接使用叠加模型；当然，如果不存在季节波动，则两种分解均可以。

![image-20200712214306301](数学建模学习笔记.assets/image-20200712214306301.png)

**时间序列分析的具体步骤**

- 处理数据的缺失值问题、生成时间变量并画出时间序列图；
- 数据是否为季度数据或者月份数据（至少有两个完整的周期，即两年），如果是的话则要观察图形中是否存在季节性波动。
- 根据时间序列图大致判断数据是否为平稳序列（数据围绕着均值上下波动，无趋势和季节性）
- 打开Spss，分析‐‐时间序列预测—创建传统模型，看看Spss专家建模器得出的最优的模型类型。
- 如果最后的结果是ARIMA(p,0,q)模型，那么我们就可以画出时间序列的样本ACF和PACF图形进行分析；如果得到的是ARIMA(p,1,q)模型，我们可以先对数据进行1阶差分后再用ACF和PACF图形分析；如果得到的结果与季节性相关，那么我们可以考虑使用时间序列分解。

## 11.1 季节性分解

> 季节性分解时时间变量不能以年为单位。

在进行时间序列分析前，需要对时间序列中的**缺失值**进行填补：

1. 缺失值发生在时间序列的`开头`或者`尾部`，可采用`直接删除`的方法；
2. 缺失值发生在序列的`中间位置`，可采用`替换`缺失值的方法。

![image-20200712215453743](数学建模学习笔记.assets/image-20200712215453743.png)

接着，定义时间变量，即把时间轴在SPSS中变成时间变量。

![image-20200712215644173](数学建模学习笔记.assets/image-20200712215644173.png)

第三步，画出并分析时间序列图，确定叠加或乘积模型。如果没规律，使用专家建模器来帮我们选择模型。

![image-20200712222053365](数学建模学习笔记.assets/image-20200712222053365.png)

第四步，如何有明显的季节性，则使用季节性分解。

![image-20200712222127901](数学建模学习笔记.assets/image-20200712222127901.png)

第五步，解读结果

![image-20200712222440537](数学建模学习笔记.assets/image-20200712222440537.png)

从表可知：第一二季度的季节因子为正，第三四季度的季节因子为负，这说明该产品一二季度的平均销量要高于三四季度，且第二季度的平均销量要高于全年平均水平20.930件，第四季度的平均销量要低于全年平均水平19.727件。

**tips**：加法季节因子的和为0 ；

如果采用`乘法`分解，那么乘法季节因子的积为1；第二季度的季节因子为1.206，则表示第二季度的平均销量是全年平均销量的1.206倍。

![image-20200712222656417](数学建模学习笔记.assets/image-20200712222656417.png)

使用季节性分解都会生成4个变量：

| 变量名   | 含义                 |
| ----- | ------------------ |
| ERR_1 | 不规则变动`I`           |
| SAS_1 | 季节性调整后系列 (`T+C+I`) |
| SAF_1 | 季节性调整因子（`S`）       |
| STC_1 | 趋势循环成分（`T+C`）      |

第六步，画出分解后的时序图

![image-20200712223153321](数学建模学习笔记.assets/image-20200712223153321.png)

第七步：分析图形

## 11.2 指数平滑模型（七种）、ARIMA模型和SRIMA模型

我们使用SPSS的专家建模器来帮我们来选择最合理的模型。

**ARIMA(0,0,0)(0,1,1)是SARIMA模型，前面代表非季节部分，后面代表季节部分**

根据专家建模器推荐的模型，来进行解释。

**专家建模器**。专家建模器会自动査找毎个相依序列的最佳拟合模型。如果指定了自变量（预测）变量，则专家建模器为 ARIMA模型中的内容选择那些与该相依序列具有统计显著关系的模型。适当时，使用差分和/或平方根或自然对数转换对模型变量进行转换。缺省情况下，专家建模器既考虑指数平滑法模型也考虑ARMA模型。但是，您可以将专家建模器限制为仅搜索ARMA模型或仅搜索指数平滑法模型，还可以指定自动检测离群值。

![image-20200713214553710](数学建模学习笔记.assets/image-20200713214553710.png)

![image-20200713214650398](数学建模学习笔记.assets/image-20200713214650398.png)

![image-20200713214721948](数学建模学习笔记.assets/image-20200713214721948.png)

注: 

（1）预测值和拟合值是不相同的，预测值是将样本外年份的数据带入模型计算得到的，而拟合值是将样本的年份重新带入模型计算得到的。

（2）这里保留残差的`ACF`和`PACF`图形可以帮助我们判断残差是否为白噪声，即该时间序列是否能被模型识别完全。**残差大于0.05则不显著，说明模型识别完全**。

![image-20200713215343523](数学建模学习笔记.assets/image-20200713215343523.png)

![image-20200713215435807](数学建模学习笔记.assets/image-20200713215435807.png)

![image-20200713215520469](数学建模学习笔记.assets/image-20200713215520469.png)

![image-20200713215736878](数学建模学习笔记.assets/image-20200713215736878.png)

![image-20200713215859279](数学建模学习笔记.assets/image-20200713215859279.png)

从残差的`ACF`和`PACF`图形中可以看出，所有滞后阶数的自相关系数和偏自相关系数均和0没有显著的差异；另外从表可以看出，对残差进行Q检验得到的p值 为0.741，即我们无法拒绝原假设，认为残差就是白噪声序列，因此温特加法模型能够很好的识别本例中的销量数据。

![image-20200713215928165](数学建模学习笔记.assets/image-20200713215928165.png)

## 11.3 时间序列的平稳性

![image-20200713213312551](数学建模学习笔记.assets/image-20200713213312551.png)

![image-20200713213324545](数学建模学习笔记.assets/image-20200713213324545.png)

## 11.4 差分方程

![image-20200713213413966](数学建模学习笔记.assets/image-20200713213413966.png)

**我们讨论的AR(p)模型一定是平稳的时间序列模型，如果原数据不平稳也要先转换为平稳的数据才能再进行建模** 

![image-20200713213517213](数学建模学习笔记.assets/image-20200713213517213.png)

## 11.5 滞后算子

![image-20200713213948825](数学建模学习笔记.assets/image-20200713213948825.png)

## 11.6 AR(p)模型

![image-20200713213802319](数学建模学习笔记.assets/image-20200713213802319.png)

小例子：

![image-20200713213820566](数学建模学习笔记.assets/image-20200713213820566.png)

# 12. 灰色预测模型

**灰色预测**对原始数据进行生成处理来寻找系统变动的规律，并生成有较强规律性的数据序列，然后建立相应的微分方程模型，从而预测事物未来发展趋势的状况。

**tips：灰色预测本质是指数预测。** 

什么时候用灰色预测？

（1）数据是以`年`为单位的`非负`数据（如果是月份或者季度数据一定要用时间序列模型）；

（2）数据能经过**准指数规律**的检验（除了前两期外，后面至少90%的期数的光滑比要低于0.5）；

（3）数据的期数较短（**3< 期数≤11**）且和其他数据之间的关联性不强，要是数据期数较长，一般用传统的时间序列模型比较合适。

## 12.1 GM(1,1)模型

`GM(1,1)`是使用原始的离散非负数据列，通过一次累加生成 削弱随机性的 较有规律的 新的离散数据列，然后通过建立微分方程模型，得到在离散点处的解 然后累减新数据的 近似估计值，从而预测原始数据的后续发展。

**第一个‘1’表示微分方程是一阶的，后面的‘1’表示只有一个变量**

![image-20200716090559215](数学建模学习笔记.assets/image-20200716090559215.png)

**GM(1,1)原理介绍**

设$x^{(0)}$=$(x^{(0)}(1), x^{(0)}(2),...,x^{(0)}(n))$ 为最初的非负数据列。我们对其进行**一次**累计得到**新的数据列**$x^{(1)}$ 

则 $x^{(1)}$=$(x^{(1)}(1), x^{(1)}(2),...,x^{(1)}(n))$

其中，$x^{(1)}(m)$=$\sum^{m}_{i=1} x^{(0)}(i)$ ，m=1,2,…,n  （这句话代表$x^{(1)}(m)$是新序列的第m个数据等于原始数据的前m个数据之和） 

令$z^{(1)}(m)$为$x^{(1)}$的**紧邻均值生成序列** ，即$z^{(1)}$=$(x^{(1)}(1), x^{(1)}(2),...,x^{(1)}(n))$

其中 $z^{(1)} (m)$=$\frac {x^{(1)}(m) + x^{(1)}(m-1)} {2}$ ，2 ≤ m ≤ n（也就是说z序列的第m个数据等于新数据列的第m个数据跟第m-1个数据的平均值）

我们称方程$x^{(0)}(k)$ + $az^{(1)}(k)$ = b 为GM(1,1)模型的基本形式。`b`表示**灰作用量**，`-a`表示**发展系数** 。发展系数越小预测的越精确。

![image-20200716092844420](数学建模学习笔记.assets/image-20200716092844420.png)

求ab的公式可以看回拟合那部分。

![image-20200716112632494](数学建模学习笔记.assets/image-20200716112632494.png)

![image-20200716112656107](数学建模学习笔记.assets/image-20200716112656107.png)

## 12.2 准指数规律的检验

> 使用灰色预测模型时需要先进行准指数检验，通过了才能使用。

如何检测？

1. $x^{(r)}$=$(x^{(r)}(1), x^{(r)}(2),...,x^{(r)}(n))$ ，定义**级比**$σ(k)$=$\frac {x^{(r)}(k)}{x^{(r)}(k-1)}$ ，r代表累加的次数一般为**1**。如果max$σ(k)$ - min$σ(k)$ < 0.5 ,则称累加r次后的序列具有**准指数规律**。
2. $x^{(1)}$的级比 $σ(k)$=$\frac {x^{(0)}(k)+x^{(1)}(k-1)} {x^{(1)}(k-1)}$ = $\frac {x^{(0)}(k)} {x^{(1)}(k-1)} +1$ ，定义原始序列$x^{(0)} $的光滑比 $ρ(k)=\frac {x^{(0)}(k)} {x^{(1)}(k-1)} $ ，因为k增加光滑比逐渐接近于0，因此要使$x^{(1)}$ 具有准指数规律，则要保证$ρ(k) ∈ (0,0.5)$ 

实际建模中，我们要计算出$ρ(k) ∈ (0,0.5)$的占比，占比越高越好。一般前两期：p（2）和p（3）可能不符合要求，我们重点关注后面的期数。

## 12.3 GM(1,1)模型的检验

![image-20200716095434492](数学建模学习笔记.assets/image-20200716095434492.png)

![image-20200716095516369](数学建模学习笔记.assets/image-20200716095516369.png)

## 12.4 GM(1,1)模型的拓展

![image-20200716095555036](数学建模学习笔记.assets/image-20200716095555036.png)

新信息GM(1,1)每次都将新预测的模型都加入到原始数据列的最后。

新陈代谢GM(1,1)每次都将新预测的模型都加入到原始数据列的最后，并把第一个数据删掉。

# 13. 神经网络

用途：

1. 拟合（非线性）
2. 判定（多类别，可与fisher一起比较）
3. 预测

模型原理可以百度相关论文，改一改就可以写上论文。

![image-20200717110145852](数学建模学习笔记.assets/image-20200717110145852.png)

![image-20200717110235117](数学建模学习笔记.assets/image-20200717110235117.png)

![image-20200717110406227](数学建模学习笔记.assets/image-20200717110406227.png)

![image-20200717110520853](数学建模学习笔记.assets/image-20200717110520853.png)

`epoch`：1个epoch等于使用训练集中的全部样本训练一次，每训练一次，神经网络

中的参数经过调整。`MSE`: 均方误差 `MSE = SSE/n`。

![image-20200717110610309](数学建模学习笔记.assets/image-20200717110610309.png)

![image-20200717110649788](数学建模学习笔记.assets/image-20200717110649788.png)

![image-20200717110726784](数学建模学习笔记.assets/image-20200717110726784.png)

![image-20200717110737389](数学建模学习笔记.assets/image-20200717110737389.png)

# 14. 规划问题

> 目标函数在一定约束条件下的极值问题（强调How）

规划分为：

- 线性规划：目标函数和约束条件都是线性（这里讲的都是变量线性）
- 非线性规划：目标函数和约束条件至少有一个是非线性
- 整数规划：解为整数，即$x_1 x_2$∈Z
- 0-1规划：解只能是0或1。（整数规划的特例）

![image-20200717153820167](数学建模学习笔记.assets/image-20200717153820167.png)

![image-20200717153802079](数学建模学习笔记.assets/image-20200717153802079.png)

## 14.1 线性规划（matlab求解）

要用matlab求解线性回归，必须满足它的规定

![image-20200717154047561](数学建模学习笔记.assets/image-20200717154047561.png)

![image-20200717154657912](数学建模学习笔记.assets/image-20200717154657912.png)

- 如果求最大值问题就要加个**负号** 使其转为最小值，结果也要加负号
- 如果出现`x1>0`的情况，可以把它变成`x1>=1` 或`-x1<=-1` (不等式约束，此时要在A,b多加一个数据)

**matlab求解线性规划linprog()步骤** 

![image-20200717155141672](数学建模学习笔记.assets/image-20200717155141672.png)

## 14.2 整数规划和0-1规划

与线性规划相比，使用的函数不同：`intlinprog()` 

**tips：这里求解的是线性**

![image-20200718082140203](数学建模学习笔记.assets/image-20200718082140203.png)

## 14.3 非线性规划

![image-20200718100706920](数学建模学习笔记.assets/image-20200718100706920.png)

![image-20200718101551448](数学建模学习笔记.assets/image-20200718101551448.png)

**`fmincon`函数的使用：** 

![image-20200718115610368](数学建模学习笔记.assets/image-20200718115610368.png)

## 14.4 Lingo

**模型的一般形式与前面提到的一致。除了最值之外** 

基于集合的专业模型

```Lingo
!注释;
!lingo不区分大小写;
MODEL:

sets:
集合定义部分（每个语句都要有分号）
endsets

data:
数据定义部分（每个语句都要有分号）
enddata

目标函数与约束条件定义部分（每个语句都要有分号）

END
```

逻辑运算符：（仅在集合遍历函数或集合操作函数中使用）

| \#eq# | 相等  | \#ge# | 大于等于 | \#not# | 逻辑非 |
| ----- | --- | ----- | ---- | ------ | --- |
| \#ne# | 不等  | \#lt# | 小于   | \#and# | 逻辑与 |
| \#gt# | 大于  | \#le# | 小于等于 | \#or#  | 逻辑或 |

常用函数：

- 幂函数：`@sqr(x)` x的平方、`@sqrt(x)` 、`@pow(x,2)` 
- 指数函数和对数函数：`@exp(x)`、`@log(x)`、`@log10(x)` （普通对数需要使用换底公式变成**ln/ln** 或**lg/lg** 的形式）
- @abs(x)：绝对值
- @smax(x1, x2, x3… xn)：返回最大值
- @smin(x1, x2, x3, … xn)：返回最小值

变量定界函数：（x默认是大于等于0）

- @bin(x)：限制x为01变量，用于**01规划**。
- @gin(x)：取整数。用于**整数规划**
- @free(x)：x取任意实数值
- @bnd(x, lb ub)：限制x的上下界

三目表达式：`if(逻辑值, 真时的结果, 假时的结果)` 

**?**为占位符，需要手动输入。如`变量 = ?;` 

集合遍历函数：

@for(s:e)：对集合s中的每一个元素都生成一个约束条件表达式，具体约束由e描述。

@sum(s:e)：对集合s中的每一个元素，计算表达式e的值，然后返回这些值的和

@max(s:e)：对集合s中的每一个元素，计算表达式e的值，然后返回这些值的最大值

@min(s:e)：对集合s中的每一个元素，计算表达式e的值，然后返回这些值的最小值

@prod(s:e)：对集合s中的每一个元素，计算表达式e的值，然后返回这些值的乘积

集合操作函数：

@in(s:e)：如果元素e在集合s中，返回1

@size(s)：返回集合中s的元素个数

@index(s:ek)：返回ek在集合s中的顺序号（从1开始）

### 原始集合和派生集合定义

定义**原始集合**的语法：`集合名 [/集合的元素列表/] [:集合的属性列表]` 

**tips：**属性之间只能有逗号分隔。

![image-20200903161731146](数学建模学习笔记.assets/image-20200903161731146.png)

定义派生集合：`派生集合名(原始集合1, 原始集合2,...原始集合n)[/元素列表/] [:a,b,c...n]` 

不指定元素列表的话默认将所有原始集合的所有元素都作为元素列表。

此方式也叫作**稠密集合**。反之叫做**稀疏集合**。

稠密集合定义方式：

![image-20200903161751613](数学建模学习笔记.assets/image-20200903161751613.png)

稀疏集合定义方式：

```
f/a1..a3/;
s/b1..b4/;
!&1表示第一个集中的下标 &2表示第二个集中的下标;
link(f,s)|&1 #le# &2;
```

**tips：`|`相当于过滤器** 

### 建立模型并求解

1. 定义集合、向量（属性）
   
   定义货物集合：`item/1..10/:w, p, x;`  
   
   解释：有10个货物，包含了三个属性w重量，p价值，x决策变量

2. 在**data**段中给**常量**赋值
   
   ```
   data:
   
   w = 6 3 4 5 1 2 3 5 4 2;
   p = 540 200 180 350 60 150 280 450 320 120;
   
   enddata
   ```

3. 目标函数的表达
   
   `max = @sum(item(i):p(i)*x(i));` 

4. 约束条件的表达
   
   重量不超过30吨：`@sum(item(i):w(i)*x(i)) <= 30;`
   
   01变量：`@for(item(i): @bin(x(i)));` 

5. 模型求解

完整代码：

```Lingo
MODEL:

sets:
item/1..10/: w, p, x;
endsets

data:
w = 6 3 4 5 1 2 3 5 4 2;
p = 540 200 180 350 60 150 280 450 320 120;
enddata

@sum(item(i):w(i)*x(i)) <= 30;
@for(item(i): @bin(x(i)));

max = @sum(item(i):p(i)*x(i));

end
```

### 访问外部数据

1. 剪切板方式：直接copy

2. 访问文本文件：`@file(路径)`【读】跟`@text(路径)`【写】 ，文件中可以的字段需要用`~`分隔。字段里的数据用**空格**分隔。
   
   ```
   data:
   item, w, p = @file('E:/桌面/test.txt');
   @text('E:/桌面/testWrite.txt') = x;
   enddata
   ```

3. 电子表格：
   
   `变量列表 = @ole(路径, '数据块名称1', '数据块名称2'...);`  【读】
   
   `@ole(路径, '数据块名称1', '数据块名称2'...) = 变量;`【写】
   
   【注意】
   
   需要先给Excel定义数据块（选中数据，右键选 定义名称）。
   
   访问Excel数据前要先的打开相应的数据文件。
   
   【例子】
   
   ![image-20200904131504418](数学建模学习笔记.assets/image-20200904131504418.png)

# 15. 主成分分析 和 因子分析

## 15.1 主成分分析

主成分分析(Principal Component Analysis)是一种**降维**算法，它能将多个指标转换为少数几个主成分，这些主成分是原始变量的**线性组合**，且彼此之间**互不相关**，其能反映出原始数据的大部分信息。

**计算步骤**

![image-20200720091608068](数学建模学习笔记.assets/image-20200720091608068.png)

1. 对矩阵x进行标准化
   
   ![image-20200720091640658](数学建模学习笔记.assets/image-20200720091640658.png)

2. 计算标准化样本的协方差矩阵
   
   ![image-20200720091723933](数学建模学习笔记.assets/image-20200720091723933.png)

3. **【小技巧】**前面两步可以合成一步：直接计算矩阵**`x`的样本相关系数矩阵** 
   
   ![image-20200720091802559](数学建模学习笔记.assets/image-20200720091802559.png)

4. 计算`R` 的特征值、特征向量和`p`
   
   ![image-20200720092114758](数学建模学习笔记.assets/image-20200720092114758.png)

5. 计算主成分贡献率以及累计贡献率
   
   ![image-20200720092342661](数学建模学习笔记.assets/image-20200720092342661.png)

6. 确定主成分
   
   6.1 找到 **累计贡献率** 第一个超过`80%`（可调整大小）的 **特征向量**
   
   6.2  位于该特征向量 前面的特征向量（包含自身）都作为主成分。
   
   ![image-20200720093218643](数学建模学习笔记.assets/image-20200720093218643.png)

7. 根据系数分析主成分代表的意义
   
   ![image-20200720093301014](数学建模学习笔记.assets/image-20200720093301014.png)

**主成分分析的困难之处主要在于要能够给出主成分的较好解释，所提取的主成分中如有一个主成分解释不了，整个主成分分析也就失败了** 

## 15.2 因子分析

因子分析法通过研究变量间的相关系数矩阵，把这些变量间错综复杂的关系归结成少数几个综合因子。而这些因子会比主成分好解释。

主成分是每个指标的线性组合，而因子分析是指标可以由什么因子线性组合，这些因子就是我们要的。

下面看看因子分析模型：**【注意】指标要标准化**

![image-20200723104733380](数学建模学习笔记.assets/image-20200723104733380.png)

**SPSS求解步骤：**

![image-20200723105047903](数学建模学习笔记.assets/image-20200723105047903.png)

![image-20200723105118162](数学建模学习笔记.assets/image-20200723105118162.png)

`KMO`检验标准：`KMO>09`，非常适合；`0.8<KMO<0.9`，适合；`07<KMO<0.8`，一般；`0.6<KMO<0.7`不太适合；`KMO<0.5`，不适合。

**巴特利特球形**检验：一般要`大于0.05`，拒绝原假设；认为相关系数不可能是单位阵，即原始变量之间存在相关性，适合于作因子分析。

![image-20200723105735682](数学建模学习笔记.assets/image-20200723105735682.png)

![image-20200723105811020](数学建模学习笔记.assets/image-20200723105811020.png)

**结果分析** 

第一次运行因子分析的结果一般作为参考，首先我们要确定原始数据是否适合进行因子分析，即能否通过`KMO`检验和`巴特利特球形`检验。

![image-20200723110043004](数学建模学习笔记.assets/image-20200723110043004.png)

![image-20200723110215992](数学建模学习笔记.assets/image-20200723110215992.png)

**碎石检验**（scree test）是根据碎石图来决定因素数的方法。Kaiser提出，可通过直接观察特征值的变化来决定因素数。当某个特征值较前一特征值的值出现较大的下降，而这个特征值较小，其后面的特征值变化不大，说明添加相应于该特征值的因素只能增加很少的信息，所以前几个特征值就是应抽取的公共因子数。

**tips：** 碎石图得到的因子数只起到参考作用；在因子分析应用于某些专业问题上时，可能事先我们已经知道了最后要确定的因子数，这时候碎石图的意义就不大了

**调整因子个数重新计算** 

![image-20200723110458667](数学建模学习笔记.assets/image-20200723110458667.png)

![image-20200723110822628](数学建模学习笔记.assets/image-20200723110822628.png)

![image-20200723110923492](数学建模学习笔记.assets/image-20200723110923492.png)

上表为总方差解释表，给出了每个公共因子所解释的方差及累计和。从“初始特征值”一栏中可以看出，前2个公共因子解释的累计方差达93.747%，而后面的公共因子的特征值较小，对解释原有变的贡献越来越小，因此提取两个公共因子是合适的。

“提取载荷平方和” 一栏是在**未旋转时**被提取的2个公共因子的方差贡献信息，其与“初始特征值”栏的前两行取值一样。

“旋转载荷平方和”是**旋转后**得到的新公共因子的方差贡献信息，和未旋转的贡献信息相比，每个公共因子的方差贡献率有变化，但**最终的累计方差贡献率不变** 

![image-20200723111204686](数学建模学习笔记.assets/image-20200723111204686.png)

“旋转后的成分矩阵”是经过旋转后的**因子载荷**矩阵，因子载荷是变量与公共因子的相关系数，当某变量在某公共因子中的载荷绝对值越大，表明该变量与该公共因子更密切。

由此可知，本例中的第1个公共因子更能代表后面五个变量，我们可以称为长跑因子（或耐力因子）；第2个公共因子更能代表前三个变量，我们可称为短跑因子（爆发力因子）

![image-20200723112141415](数学建模学习笔记.assets/image-20200723112141415.png)

![image-20200723112152556](数学建模学习笔记.assets/image-20200723112152556.png)

和主成分分析一样，我们可以用因子得分1和位2作为两个新的变量，来进行后续的建模（例如聚类、回归等）

# 16. 粒子群算法

## 16.1 简单介绍

粒子群算法是一个智能算法，其全称为粒子群优化算法（ Particle Swarm Optimization，PSO）.它是通过 *模拟鸟群觅食行为而发展起来的一种基于群体协作的搜索算法*。

> Kennedy J , Eberhart R . Particle swarm optimization[C]// Proceedings of ICNN'95 ‐ International Conference on Neural Networks. IEEE, 1995

> 优化问题可分为两大类：一类是具有连续型的变量，比如我们之前探究的求函数最值的问题，称为**连续优化问题**；另一类是具有离散型的变量，例如0‐1规划问题、TSP旅行商问题，称为**组合优化问题**。
> 
> 而**粒子群**可以很好的解决**连续优化问题**，后续的**模拟退火**可以很好的解决**组合优化**问题。

什么是启发式算法？

启发式算法是一个基于直观或经验构造的算法，在**可接受的花费**（时间和空间）下给出待解决**优化问题**的一个**可行解**。

什么是**启发式搜索算法**？

在搜索过程中使用了获取的中间信息来改进策略，例如粒子群、模拟退火、遗传、蚁群。反之为盲目搜索，比如蒙特卡罗。

**基本概念：**

- 粒子：优化问题的候选解
- 位置：候选解所在的位置
- 速度：候选解移动的速度
- 适应度：评价粒子优劣的值，一般设置为目标函数值
- 个体极值：单个粒子迄今为止找到的最佳位置
- 群体极值：所有粒子迄今为止找到的最佳位置

粒子群算法的**基本核心**是利用群体中的个体对信息的共享从而使整个群体的运动在问题求解空间中产生从无序到有序的演化过程，从而获得问题的最优解。

![image-20200822110018548](数学建模学习笔记.assets/image-20200822110018548.png)

![image-20200822110221050](数学建模学习笔记.assets/image-20200822110221050.png)

**tips：**

1. $r_1 r_2$ 是**[0，1]**的随机数
2. 惯性权重取0.9 ~ 1.2是比较合适的，一般取**0.9**就行
3. 个体学习因子和社会(或群体)学习因子取 **2** 比较合适

**流程图**如下：

![image-20200822110151698](数学建模学习笔记.assets/image-20200822110151698.png)

## 16.2 粒子群的改进

### 16.2.1 线性递减惯性权重

惯性权重w体现的是粒子继承先前的速度的能力，**一个较大的惯性权值有利于全局搜索，而一个较小的权值则更利于局部搜索** ，所以我们需要在一开始倾向于全局搜索，最后倾向于局部搜索。为了更好地平衡算法的全局搜索以及局部搜索能力，Shi,Y提出了<u>线性递减惯性权重</u>LDIW(Linear Decreasing Inertia Weight),公式如下

$w^d = w_{start} - (w_{start} - w_{end}) × \frac {d}{K}$ 

d为当前迭代的次数，K为总迭代次数。

$w_{start}$一般取0.9，$w_{end}$一般取0.4

### 16.2.2 自适应惯性权重

自适应惯性权重说的是惯性权重随着适应度的大小而决定其大小。

一个较大的惯性权值有利于全局搜索而一个较小的权值则更利于局部搜索

![image-20200822111412815](数学建模学习笔记.assets/image-20200822111412815.png)

![image-20200822111428704](数学建模学习笔记.assets/image-20200822111428704.png)

### 16.2.3 随机惯性权重

顾名思义就是值惯性权重是随机的。

使用随机的惯性权重，可以避免在迭代前期局部搜索能力的不足；也可以避免在迭代后期全局搜索能力的不足

### 16.2.4 压缩因子法

个体学习因子cl和社会(群体)学习因子c2决定了粒子本身经验信息和其他粒子的经验信息对粒子运行轨迹的影响，其反映了粒子群之间的信息交流。设置c1较大的值，会使粒子过多地在自身的局部范围内搜索，而较大的c2的值，则又会促使粒子过早收敛到局部最小值。

为了有效地控制粒子的飞行速度，使算法达到全局搜索与局部搜索两者间的有效平衡，**Clerc构造了引入收缩因子的PSO模型，采用了压缩因子，这种调整方法通过合适选取参数，可确保PSO算法的收敛性，并可取消对速度的边界限制。**

![image-20200822112301202](数学建模学习笔记.assets/image-20200822112301202.png)

### 16.2.5 优化问题的测试函数

当你提出了一种新的优化算法后，你需要和别人之前提出的算法来进行PK，看你的算法有没有提高，下表给出了四种常见的测试函数

![image-20200822112408326](数学建模学习笔记.assets/image-20200822112408326.png)

• 维数：自变量x的个数

• 取值范围：每个x对应的变化范围

• 理论极值：这个函数理论上的最小值

• 误差目标：只要我们求出来的最小值小于这个目标值就能被接受

### 16.2.6 自动退出迭代循环

当粒子已经找到最佳位置后，再增加迭代次数只会浪费计算时间，所以我们可以设计一个容忍度，来记录变化量很小的次数，若连续次数达到容忍度则跳出循环，结束算法。

## 16.3 Matlab自带的粒子群函数

Matlab中`particleswarm`函数采用的是自适应的领域模式。

【注意】粒子群函数也默认是求**最小值**。

`[x, fval, exitflag, output] = particleswarm(@fun, nvars, Ib, ub, options)`

- x为最佳位置
- fval为最小值
- exitflag为返回标志
- output可以体现迭代次数和解释退出标志
- fun为函数文件（包含目标函数）
- nvars为变量个数
- Ib ub为变量的取值范围
- options为设置粒子群函数的一些选项

**预设参数**：

1. 粒子个数 Swarmsize
   
   默认设置为：min{100，10* nears}， nears是变量个数

2. 惯性权重 InertiaRange
    默认设置的范围为：[0.1，1.1]；注意，在迭代过程中惯性权重会采取自适应措施随着迭代过程不断调整。

3. 个体学习因子 SelfAdjustmentWeight
    默认设置为：1.49（和压缩因子的系数几乎相同）

4. 社会学习因子 SocialAdjustmentWeight
    默认设置为：1.49（和压缩因子的系数几乎相同）

5. 领域内粒子的比例 MinNeighborsFraction
    默认设置为：0.25，由于采取的是领域模式，因此定义了一个“领域最少粒子数目"：minNeighborhoodSize=max{2，（粒子数目*领域内粒子的比例）的整数部分}，在迭代开始后，每个粒子会有一个领域，初始时领域内的粒子个数（记为Q就等于“邻域最少粒子数目"，后续邻域域内的粒子个数Q会自适应调整。

**变量初始化和适应度的计算**

（1）速度初始化：和我们之前的类似，只不过最大速度就是上界和下界的差额
 `vmax = ub-lb；` `V = -vmax + 2*vmax .* rand(n, narvs)` 

其他都跟前面的差不多。

**修改参数options**：

![image-20200822121624901](数学建模学习笔记.assets/image-20200822121624901.png)

如：

```matlab
options = optimoptions('particleswarm',
                        'FunctionTolerance',1e-12,
                        'MaxStallIterations',50,
                        'MaxIterations',20000,
                        'HybridFcn',@fmincon);
[x,fval] = particleswarm(@Obj_fun3,narvs,x_lb,x_ub,options)
```

# 17. 微分方程模型

> 当我们描述实际对象的**某些特性**随**时间（空间）**而演变的过程、分析它的**变化规律**、预测它的**未来形态**、研究它的**控制手段**时。通常要建立对象的动态模型。

## 17.1 基本概念

- 微分方程：含导数或微分的方程。其一般形式为$f(x,y,y',y''...y^{(n)}) = 0$ 
  - 常微分方程：未知函数是一元函数
  - 偏微分方程：未知函数是多元函数
- 通解：解是一个含有常数C的表达式
- 特解：也叫解析解，**解析解+常数为通解** 。（只有给出了初始条件才可以求出特解）
- 数值解：解析解在一个区间无限细分下求的具体解。

## 17.2 dsolve求解析解

`dsolve('f1','f2',…,'fn',’初始条件’,’自变量’)`

- f1、f2是微分方程(组)，导数需要写出`Dy`的形式，如`y-y'=2x`要写成`y-Dy = 2*x` 
- 表示导数的阶数`Dn`，如`D2y`表示y的二阶导
- 初始条件可以不给，若不给，求出的则是通解。多个初始条件之间用`,`隔开

例子：

**一阶导**

```matlab
% 求y-y'=2x的通解
x = dsolve('y-Dy = 2*x','x')
% 结果
% x = 2*x + C1*exp(x) + 2
```

**二阶导**

```matlab
% 求y''+4y'+19y=0且y(0)=0,y'(0)=15
x = dsolve('D2y+4*Dy+19*y = 0', 'y(0)=0,Dy(0)=15','x')
% 结果
% x = 15^(1/2)*exp(-2*x)*sin(15^(1/2)*x)

% 将结果转为latex代码
latex(x) % \sqrt{15}\, \mathrm{e}^{- 2\, x}\, \sin\!\left(\sqrt{15}\, x\right)
```

**方程组**

![image-20200727100917499](数学建模学习笔记.assets/image-20200727100917499.png)

```matlab
y1 = 'Dx = 2*x-3*y+3*z+t';
y2 = 'Dy = 4*x-5*y+3*z+t';
y3 = 'Dz = 4*x-4*y+2*z+t';
% 得到3个结果，需分别接收
[x,y,z] = dsolve(y1,y2,y3,'t')
% 对结果进行化简
simplify(x)
simplify(y)
simplify(z)
```

## 17.3 ode45求数值解

在大多数情况下是求不出解析解的，此时退而求其次，求数值解。在建模时，都要先尝试看有无解析解，再求解数值解。

matlab中求解数值解的方法有很多，其中`ode45`使用的最多。

***

**ode45**

`[x,y] = ode45(@m, [xs,xe], y0, options)` 

- 如果是方程组，则得到的`x`跟`y`都是**列向量**
- `m`为`m文件`，里面写微分方程(组)的 **标准形式**。
  - ![标准形式](数学建模学习笔记.assets/image-20200727102539541.png)
- `[xs, xe]` 表示自变量的取值范围。
- `y0`为初始值，即**左边界的函数值**，若求解的是**n个**方程，则初始值要为**n维**的向量
- options可以设置精度，一般不指定。

例子

**一阶方程**

![image-20200727103314491](数学建模学习笔记.assets/image-20200727103314491.png)

**一阶方程组** 

![image-20200727104958794](数学建模学习笔记.assets/image-20200727104958794.png)

```matlab
function dy = df(x, y)
    % 要初始化dy 有多少个方程组就初始化多少列
    dy = zeros(3,1);
    % 注意这里是小d
    dy(1) = y(2) * y(3);
    dy(2) = - y(1) * y(3);
    dy(3) =-0.51 * y(1) * y(2);
end
```

调用：`[x, y] = ode45(@df, [0 4*pi], [0 1 1])` 

**多阶方程组** 

> 求解多阶方程的时候，需要引入变量来**降阶**。

![image-20200727105518011](数学建模学习笔记.assets/image-20200727105518011.png)

```
令 y1 = y，y1' = y2;
则 y1(-2) = 3; y2(-2) = 4
   y2' = 2xy1/(1+x^2)
```

m文件：

```matlab
function dy = df2(x,y)
    dy = zeros(2,1);
    dy(1) = y(2);
    dy(2) = 2*x*y(1)/(1+x.^2);
end
```

调用：`[x, y] = ode45(@df2, [-2 2], [3 4])` 

***

**小扩展**

`ode45`只能求非刚性的问题，而 `ode15s`可以解决刚性问题。

**刚性**是指 函数在某个短时间内发生剧烈的变化

## 案例1：传染病模型

专业术语

| 感染者：S | 患者：I | 治愈者：R | 潜伏者：E |
| ----- | ---- | ----- | ----- |
|       |      |       |       |

整体人数：N = S + I + E

画出之间的感染图，列出微分方程。如$\frac {dI}{dt} = β\frac {SI}{N}$ 

**如果有成员移除系统，则整体人数N会变。**

思路扩展：

1. 治愈者不完全有抗体，有一部分仍会变成感染者。
2. 患者有一部分会因病死亡
3. 潜伏者可能也会传染
4. 整体考虑出生率和死亡率

# 18. 模拟退火 SA

模拟退火算法（ Simulated Annealing algorithm，简记为SAA或SA），它是基于金属退火机理而建立起来的一种最优化方法，它能够以随机搜索技术从概率意义上找出目标函数的全局最值点。

模拟退火参数的选择至关重要，**初始参数**的合理选取是保证算法的全局收敛性和效率的关键，选择不当得到的结果可能会很差。

## 18.1 爬山法

![image-20200824105020793](数学建模学习笔记.assets/image-20200824105020793.png)

以最简单的连续一元函数找最大值为例来介绍爬山法

1. 在解空间中随机生成一个初始解
2. 根据初始解的位置，我们在下一步有两种走法：向左邻域走一步或者向右邻
   域走一步（走的步长越小越好，但会加大计算量）
3. 比较不同走法下目标函数的大小，并决定下一步往哪个方向走。上图中向左
   走目标函数较大，因此我们应该往左走一小步
4. 不断重复这个步骤，直到找到一个极大值点（或定义域边缘处），此时我们就
   结束搜索

## 18.2 模拟退火的介绍

> 个人看法：可以将模拟退火看成是升级版的蒙特卡罗

模拟退火跟爬山法基本差不多，只不过它会有一定的概率来接受不理想的结果，也就是说在爬山法的第三步，当我们现在找到的值小于之前找到的值时，模拟退火不会直接拒绝我们现在找到的值，而是以一定的概率p接受它。然后一直重复前面的步骤。

很明显，p应该是[0，1]上的随时间增加而递减的数。

所以我们可以设 **$p_t = e^{-\frac {|f(B)-f(A)|}{C_t}}$** ，$C_t$一般取$100×0.95^t $ 

1. 温度一定时，△f越小，概率越大，即目标函数相差越小，接受的可能性越大。
2. △f一定时，温度越高，概率越大，即搜索前期温度较高时更有可能接受新解。

**【注意】对每个t迭代的同时还需要对每个t下的温度进行多次迭代。** 

# 19 图形处理

## 19.1 SVD压缩图片

奇异值分解（Singular Value Decomposition）是线性代数中一种重要的矩阵分解，其在图形学、统计学、推荐系统、信号处理等领域有重要应用。

它的原理是利用减少矩阵的秩的数量来进行矩阵的压缩。

将矩阵A 分解为：$A_{m×n}$ = $U_{m×m}$ $S_{m×n}$ $V^{T}_{n×n}$ ，然后根据S矩阵来删除比较小的值。

![image-20210119204143087](数学建模学习笔记.assets/image-20210119204143087.png)

Matlab进行奇异值分解：`[U,S,V] = svd(A)` 注意这里的**V没有转置**

**如果是彩色图片需要对3个维度的矩阵分别进行压缩。**

## 19.2 将视频分离为图片

```matlab
%% 读取视频
video_file='视频路径';
video=VideoReader(video_file); 
frame_number = video.NumberOfFrames; %视频的总帧数

%% 分离图片
for i=1:30:frame_number % 这里演示的是每30帧数保存一次
    image_name=strcat('保留图片的路径',num2str(i),'.jpg');
    Photo=read(video,i); % 读出所在帧的图片对象
    imwrite(Photo,image_name); %将图片保存到指定的位置
end
```

## 19.3 批量处理文件夹内的所有图片

```matlab
folder_name = '文件夹路径'; 
dirOutput = dir(fullfile(folder_name, '*.jpg')); 
files = {dirOutput.name}; 
n = length(files); 
ratio = 0.9; 
for i = 1:n 
    name = files(i){1}; % 元胞矩阵变成字符串
    photo_address = fullfile(folder_name, name); 
    disp(photo_address)
    save_address = fullfile(folder_name, name);
    % 自定义的压缩函数
    photo_compress(photo_address, save_address, ratio) 
end
```
